"""–ü–∞—Ä—Å–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã boost –∫–ª—É–±–∞."""

import logging
import asyncio
import re
from typing import Optional, Dict, Any, List
from bs4 import BeautifulSoup
import requests

from config import BASE_URL, CLUB_BOOST_PATH, PARSE_INTERVAL_SECONDS
from timezone_utils import ts_for_db, now_msk
from rank_detector import RankDetectorImproved
from weekly_stats import (
    parse_weekly_contributions,
    compute_stats_hash,
    save_weekly_contributions,
    send_or_update_weekly_pinned,
    get_week_start,
)

logger = logging.getLogger(__name__)


class BoostPageParser:
    """–ü–∞—Ä—Å–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã boost –∫–ª—É–±–∞."""

    def __init__(self, session: requests.Session, rank_detector: RankDetectorImproved):
        self.session = session
        self.rank_detector = rank_detector
        self.url = f"{BASE_URL}{CLUB_BOOST_PATH}"
        self._consecutive_errors = 0
        self._max_consecutive_errors = 5

    def parse(self) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É boost."""
        try:
            response = self.session.get(self.url)

            if response.status_code != 200:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status_code}")
                self._mark_error()
                return None

            soup = BeautifulSoup(response.text, "html.parser")

            card_id = self._extract_card_id(soup)
            if not card_id:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å card_id")
                self._mark_error()
                return None

            card_image_url = self._extract_card_image(soup)
            replacements = self._extract_replacements(soup)
            daily_donated = self._extract_daily_donated(soup)
            club_owners = self._extract_club_owners(soup)

            self._mark_success()

            return {
                "card_id":        card_id,
                "card_rank":      "?",
                "card_image_url": card_image_url,
                "replacements":   replacements,
                "daily_donated":  daily_donated,
                "club_owners":    club_owners,
                "discovered_at":  ts_for_db(now_msk()),
            }

        except (requests.exceptions.ProxyError,
                requests.exceptions.ConnectionError,
                requests.exceptions.Timeout) as e:
            self._mark_error()
            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {type(e).__name__}")
            return None

        except Exception as e:
            self._mark_error()
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return None

    def fetch_weekly_ajax(self) -> Optional[str]:
        """
        –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç AJAX-—ç–Ω–¥–ø–æ–∏–Ω—Ç –Ω–µ–¥–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–ª—É–±–∞.

        –ê–ª–≥–æ—Ä–∏—Ç–º (–ø—Ä–æ–≤–µ—Ä–µ–Ω debug_csrf2.py):
        1. GET —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±—É—Å—Ç–∞ —á–µ—Ä–µ–∑ inner._session ‚Äî –ø–æ–ª—É—á–∞–µ–º meta csrf-token
        2. POST /clubs/getTopUsers?period=week —á–µ—Ä–µ–∑ —Ç—É –∂–µ inner —Å–µ—Å—Å–∏—é
           —Å X-CSRF-TOKEN –∏–∑ meta —Ç–µ–≥–∞

        –í–∞–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å inner._session –Ω–∞–ø—Ä—è–º—É—é ‚Äî RateLimitedSession
        –Ω–µ –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç –∫—É–∫–∏ –¥–æ–º–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–∏ POST.
        """
        # –í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ–º —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Å–µ—Å—Å–∏—é requests.Session
        inner = self.session._session if hasattr(self.session, '_session') else self.session
        ajax_url = f"{BASE_URL}/clubs/getTopUsers?period=week"

        try:
            # –®–∞–≥ 1: GET —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±—É—Å—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ–∂–µ–≥–æ meta csrf-token
            resp = inner.get(self.url, timeout=15)
            if resp.status_code != 200:
                logger.warning(
                    f"[Weekly AJAX] GET –±—É—Å—Ç–∞ –≤–µ—Ä–Ω—É–ª {resp.status_code}"
                )
                return None

            soup = BeautifulSoup(resp.text, "html.parser")
            meta = soup.find("meta", {"name": "csrf-token"})
            if not meta:
                logger.warning("[Weekly AJAX] meta[name=csrf-token] –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return None

            meta_token = meta.get("content", "")
            if not meta_token:
                logger.warning("[Weekly AJAX] meta csrf-token –ø—É—Å—Ç–æ–π")
                return None

            logger.debug(f"[Weekly AJAX] meta csrf-token –ø–æ–ª—É—á–µ–Ω: {meta_token[:20]}...")

            # –®–∞–≥ 2: POST —Å meta —Ç–æ–∫–µ–Ω–æ–º —á–µ—Ä–µ–∑ —Ç—É –∂–µ inner —Å–µ—Å—Å–∏—é
            ajax_resp = inner.post(
                ajax_url,
                headers={
                    "X-CSRF-TOKEN":     meta_token,
                    "X-Requested-With": "XMLHttpRequest",
                    "Referer":          self.url,
                    "Accept":           "*/*",
                },
                data=None,
                timeout=15,
            )

            logger.info(
                f"[Weekly AJAX] POST {ajax_url} ‚Üí HTTP {ajax_resp.status_code}"
            )

            if ajax_resp.status_code != 200:
                logger.warning(
                    f"[Weekly AJAX] –ù–µ—É—Å–ø–µ—à–Ω—ã–π —Å—Ç–∞—Ç—É—Å: {ajax_resp.status_code}"
                )
                return None

            # –û—Ç–≤–µ—Ç ‚Äî JSON –≤–∏–¥–∞ {"content": "<html...>"}
            try:
                data = ajax_resp.json()
                content = data.get("content", "")
                if content:
                    items = content.count("club-boost__top-item")
                    logger.info(
                        f"[Weekly AJAX] –ü–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç ({len(content)} –±–∞–π—Ç, "
                        f"~{items // 2} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤)"
                    )
                    return content
                logger.warning(
                    f"[Weekly AJAX] JSON –±–µ–∑ –ø–æ–ª—è 'content'. "
                    f"–ö–ª—é—á–∏: {list(data.keys())}"
                )
                return None
            except ValueError:
                if "club-boost__top" in ajax_resp.text:
                    logger.info(
                        f"[Weekly AJAX] –ü–æ–ª—É—á–µ–Ω raw HTML ({len(ajax_resp.text)} –±–∞–π—Ç)"
                    )
                    return ajax_resp.text
                logger.warning(
                    f"[Weekly AJAX] –û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. "
                    f"–ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {ajax_resp.text[:200]}"
                )
                return None

        except Exception as e:
            logger.error(f"[Weekly AJAX] –û—à–∏–±–∫–∞: {e}", exc_info=True)
            return None

    def _mark_success(self):
        self._consecutive_errors = 0

    def _mark_error(self):
        self._consecutive_errors += 1
        if self._consecutive_errors >= self._max_consecutive_errors:
            logger.warning(
                f"‚ö†Ô∏è {self._consecutive_errors} –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ–¥—Ä—è–¥"
            )

    def _extract_card_id(self, soup: BeautifulSoup) -> Optional[int]:
        link = soup.select_one('a[href*="/cards/"][href*="/users"]')
        if link:
            href = link.get("href", "")
            match = re.search(r'/cards/(\d+)/users', href)
            if match:
                return int(match.group(1))
        return None

    def _extract_card_image(self, soup: BeautifulSoup) -> str:
        img = soup.select_one('.club-boost__image img')
        if img:
            src = img.get("src", "")
            if src:
                if src.startswith("/"):
                    return f"{BASE_URL}{src}"
                return src
        return ""

    def _extract_replacements(self, soup: BeautifulSoup) -> str:
        text = soup.get_text()
        match = re.search(r'(\d+)\s*/\s*(\d+)', text)
        if match:
            return f"{match.group(1)}/{match.group(2)}"
        return "0/10"

    def _extract_daily_donated(self, soup: BeautifulSoup) -> str:
        text = soup.get_text()
        matches = re.findall(r'(\d+)\s*/\s*(\d+)', text)
        if len(matches) >= 2:
            return f"{matches[1][0]}/{matches[1][1]}"
        return "0/50"

    def _extract_club_owners(self, soup: BeautifulSoup) -> List[int]:
        owner_ids = []
        owners_block = soup.select_one('.club-boost__owners-list')
        if owners_block:
            links = owners_block.select('a[href*="/users/"]')
            for link in links:
                href = link.get("href", "")
                match = re.search(r'/users/(\d{1,7})', href)
                if match:
                    owner_ids.append(int(match.group(1)))
        return owner_ids


async def parse_loop(session: requests.Session, bot, rank_detector: RankDetectorImproved):
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –Ω–µ–¥–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–∫–ª–∞–¥–æ–≤."""
    from database import get_current_card, archive_card, insert_card
    from notifier import notify_owners, notify_group_new_card
    from card_info_parser import get_card_name, get_owners_nicknames
    from weekly_stats import get_week_contributions_from_db, ensure_weekly_tables

    parser = BoostPageParser(session, rank_detector)
    logger.info("üîÑ –ó–∞–ø—É—â–µ–Ω —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã boost")

    consecutive_failures = 0
    max_consecutive_failures = 5

    last_weekly_hash: Optional[str] = None
    last_week_start: str = get_week_start()
    weekly_check_counter: int = 0
    WEEKLY_CHECK_EVERY = 10

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑ –ë–î –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    await ensure_weekly_tables()
    startup_contribs = await get_week_contributions_from_db(last_week_start)
    if startup_contribs:
        await send_or_update_weekly_pinned(bot, startup_contribs, last_week_start)
        last_weekly_hash = compute_stats_hash([
            {"mangabuff_id": c["mangabuff_id"], "contribution": c["contribution"]}
            for c in startup_contribs
        ])
        logger.info(
            f"üöÄ –°—Ç–∞—Ä—Ç: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–µ–¥–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ –ë–î "
            f"({len(startup_contribs)} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤)"
        )
    else:
        logger.info(
            "üöÄ –°—Ç–∞—Ä—Ç: –≤ –ë–î –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî AJAX –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–µ—Ä–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏"
        )
        weekly_check_counter = WEEKLY_CHECK_EVERY - 1

    while True:
        try:
            current = await get_current_card()
            data = parser.parse()

            if data:
                consecutive_failures = 0

                current_week_start = get_week_start()

                if current_week_start != last_week_start:
                    logger.info(
                        f"üóì –ù–æ–≤–∞—è –Ω–µ–¥–µ–ª—è: {last_week_start} ‚Üí {current_week_start}"
                    )
                    last_weekly_hash = None
                    last_week_start = current_week_start
                    weekly_check_counter = WEEKLY_CHECK_EVERY - 1

                weekly_check_counter += 1
                if weekly_check_counter >= WEEKLY_CHECK_EVERY:
                    weekly_check_counter = 0
                    loop = asyncio.get_event_loop()
                    weekly_html = await loop.run_in_executor(
                        None, parser.fetch_weekly_ajax
                    )

                    if weekly_html:
                        weekly_contributions = parse_weekly_contributions(weekly_html)

                        if weekly_contributions:
                            current_hash = compute_stats_hash(weekly_contributions)

                            if current_hash != last_weekly_hash:
                                await save_weekly_contributions(
                                    current_week_start, weekly_contributions
                                )
                                await send_or_update_weekly_pinned(
                                    bot, weekly_contributions, current_week_start
                                )
                                last_weekly_hash = current_hash
                                logger.info(
                                    f"üìä –ù–µ–¥–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ "
                                    f"({len(weekly_contributions)} —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤)"
                                )
                        else:
                            logger.warning(
                                "[Weekly AJAX] HTML –ø–æ–ª—É—á–µ–Ω, –Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–∏ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã"
                            )

                # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–º–µ–Ω—ã –∫–∞—Ä—Ç—ã
                if current is None or current.card_id != data["card_id"]:
                    logger.info(
                        f"üîÑ –°–º–µ–Ω–∞ –∫–∞—Ä—Ç—ã: "
                        f"{current.card_id if current else 'None'} ‚Üí {data['card_id']}"
                    )

                    if data["card_image_url"] and rank_detector.is_ready:
                        data["card_rank"] = rank_detector.detect_from_url(
                            data["card_image_url"], session=session
                        )
                    else:
                        data["card_rank"] = "?"

                    if current:
                        await archive_card(current.id)

                    await insert_card(data)

                    loop = asyncio.get_event_loop()

                    card_name = await loop.run_in_executor(
                        None, get_card_name, session, data["card_id"]
                    )

                    owners_nicks = []
                    if data["club_owners"]:
                        owners_nicks = await loop.run_in_executor(
                            None, get_owners_nicknames, session, data["club_owners"], 10
                        )

                    await notify_owners(bot, data)
                    await notify_group_new_card(bot, data, card_name, owners_nicks)

                    logger.info(
                        f"‚úÖ –ù–æ–≤–∞—è –∫–∞—Ä—Ç–∞ ¬´{card_name}¬ª "
                        f"ID {data['card_id']} (–†–∞–Ω–≥: {data['card_rank']}), "
                        f"–≤–ª–∞–¥–µ–ª—å—Ü–µ–≤: {len(owners_nicks)}"
                    )
            else:
                consecutive_failures += 1
                if consecutive_failures >= max_consecutive_failures:
                    logger.warning(
                        f"‚ö†Ô∏è {consecutive_failures} –Ω–µ—É–¥–∞—á –ø–æ–¥—Ä—è–¥"
                    )
                    try:
                        proxy_manager = bot._application.bot_data.get("proxy_manager")
                        if proxy_manager:
                            proxy_manager.mark_failure()
                    except Exception:
                        pass
                    consecutive_failures = 0

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            consecutive_failures += 1

        await asyncio.sleep(PARSE_INTERVAL_SECONDS)